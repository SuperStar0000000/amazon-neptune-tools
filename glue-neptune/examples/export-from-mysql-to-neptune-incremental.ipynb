{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, boto3, os, datetime\n",
    "\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.transforms import ApplyMapping\n",
    "from awsglue.transforms import RenameField\n",
    "from awsglue.transforms import SelectFields\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import format_string\n",
    "from pyspark.sql.functions import col\n",
    "from glue_neptune.NeptuneConnectionInfo import NeptuneConnectionInfo\n",
    "from glue_neptune.NeptuneGremlinClient import NeptuneGremlinClient\n",
    "from glue_neptune.GremlinCsvTransforms import GremlinCsvTransforms\n",
    "from gremlin_python import statics\n",
    "from gremlin_python.structure.graph import Graph\n",
    "from gremlin_python.process.graph_traversal import __\n",
    "from gremlin_python.process.strategies import *\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "from gremlin_python.process.traversal import *\n",
    "\n",
    "glueContext = GlueContext(sc)\n",
    "     \n",
    "job = Job(glueContext)\n",
    "job.init('mysql-to-neptune', {})\n",
    "\n",
    "database = \"sales-order\"\n",
    "order_table = \"salesdb_sales_order\"\n",
    "order_detail_table = \"salesdb_sales_order_detail\"\n",
    "\n",
    "gremlin_endpoint = NeptuneConnectionInfo(glueContext).neptune_endpoint('neptune')\n",
    "neptune = NeptuneGremlinClient(gremlin_endpoint)\n",
    "\n",
    "def get_last_checkpoint (client, tablename):\n",
    "    conn = client.remote_connection()\n",
    "    g = client.traversal_source(conn)\n",
    "    checkpoint= (g.V().hasLabel('Checkpoint').has('table', tablename).fold().coalesce(\n",
    "        __.unfold(),\n",
    "        __.addV('Checkpoint').\n",
    "        property('table', tablename).\n",
    "        property('value', datetime.datetime(2015, 1, 1, 0, 0))).\n",
    "    values('value').\n",
    "    next())\n",
    "    conn.close()\n",
    "    return checkpoint\n",
    " \n",
    "def update_checkpoint (client, tablename, checkpoint):\n",
    "    conn = client.remote_connection()\n",
    "    g = client.traversal_source(conn)\n",
    "    g.V().hasLabel('Checkpoint').has('table', tablename).property(Cardinality.single, 'value', checkpoint).next()\n",
    "    conn.close()\n",
    "    return True\n",
    "    \n",
    "checkpoint = get_last_checkpoint(neptune, order_table)\n",
    "newcheckpoint = checkpoint + datetime.timedelta(days=1)\n",
    "\n",
    "print(\"Last checkpoint: \"+ str(checkpoint))\n",
    "print(\"New checkpoint : \"+ str(newcheckpoint))\n",
    "\n",
    "print \"Creating Order vertices...\"\n",
    "\n",
    "datasource0 = glueContext.create_dynamic_frame.from_catalog(database = database, table_name = order_table, transformation_ctx = \"datasource0\")\n",
    "df0 = datasource0.toDF().filter(col(\"ORDER_DATE\") == checkpoint)\n",
    "datasource1 = DynamicFrame.fromDF(df0, glueContext,'datasource1')\n",
    "\n",
    "print \"Total orders         : \"+str(datasource0.count())\n",
    "print \"Orders for checkpoint: \"+str(datasource1.count())\n",
    "\n",
    "applymapping1 = ApplyMapping.apply(frame = datasource1, mappings = [(\"ORDER_DATE\", \"timestamp\", \"orderDate\", \"string\"), (\"SHIP_MODE\", \"string\", \"shipMode\", \"string\"), (\"SITE_ID\", \"double\", \"siteId\", \"int\"), (\"ORDER_ID\", \"int\", \"orderId\", \"int\")], transformation_ctx = \"applymapping1\")\n",
    "applymapping1 = GremlinCsvTransforms.create_prefixed_columns(applymapping1, [('~id', 'orderId', 'o')])\n",
    "selectfields1 = SelectFields.apply(frame = applymapping1, paths = [\"~id\", \"orderDate\", \"shipMode\"], transformation_ctx = \"selectfields1\")\n",
    "\n",
    "selectfields1.toDF().foreachPartition(neptune.add_vertices('Order'))\n",
    "\n",
    "print \"Creating OrderDetail vertices...\"\n",
    "\n",
    "datasource2 = glueContext.create_dynamic_frame.from_catalog(database = database, table_name = order_detail_table, transformation_ctx = \"datasource1\")\n",
    "datasource3 = datasource2.join( [\"ORDER_ID\"],[\"ORDER_ID\"], datasource1, transformation_ctx = \"join\")\n",
    "\n",
    "print \"Total order details         : \"+str(datasource2.count())\n",
    "print \"Order details for checkpoint: \"+str(datasource3.count())\n",
    "\n",
    "applymapping2 = ApplyMapping.apply(frame = datasource3, mappings = [(\"DISCOUNT\", \"decimal(10,2)\", \"discount\", \"string\"), (\"UNIT_PRICE\", \"decimal(10,2)\", \"unitPrice\", \"string\"), (\"TAX\", \"decimal(10,2)\", \"tax\", \"string\"), (\"SUPPLY_COST\", \"decimal(10,2)\", \"supplyCost\", \"string\"), (\"PRODUCT_ID\", \"int\", \"productId\", \"int\"), (\"QUANTITY\", \"int\", \"quantity\", \"int\"), (\"LINE_ID\", \"int\", \"lineId\", \"int\"), (\"LINE_NUMBER\", \"int\", \"lineNumber\", \"int\"), (\"ORDER_ID\", \"int\", \"orderId\", \"int\")], transformation_ctx = \"applymapping2\")\n",
    "applymapping2 = GremlinCsvTransforms.create_prefixed_columns(applymapping2, [('~id', 'lineId', 'od')])\n",
    "selectfields2 = SelectFields.apply(frame = applymapping2, paths = [\"~id\", \"lineNumber\", \"quantity\", \"unitPrice\", \"discount\", \"supplyCost\", \"tax\"], transformation_ctx = \"selectfields2\")\n",
    "\n",
    "selectfields2.toDF().foreachPartition(neptune.add_vertices('OrderDetail'))\n",
    "\n",
    "print \"Creating ORDER_DETAIL edges...\"\n",
    "\n",
    "applymapping3 = RenameField.apply(applymapping2, \"~id\", \"~to\")\n",
    "applymapping3 = GremlinCsvTransforms.create_prefixed_columns(applymapping3, [('~from', 'orderId', 'o')])\n",
    "applymapping3 = GremlinCsvTransforms.create_edge_id_column(applymapping3, '~from', '~to')\n",
    "selectfields3 = SelectFields.apply(frame = applymapping3, paths = [\"~id\", \"~from\", \"~to\", \"lineNumber\"], transformation_ctx = \"selectfields3\")\n",
    "\n",
    "selectfields3.toDF().foreachPartition(neptune.add_edges('ORDER_DETAIL'))\n",
    "\n",
    "print \"Creating PRODUCT edges...\"\n",
    "\n",
    "applymapping4 = RenameField.apply(applymapping2, \"~id\", \"~from\")\n",
    "applymapping4 = GremlinCsvTransforms.create_prefixed_columns(applymapping4, [('~to', 'productId', 'p')])\n",
    "applymapping4 = GremlinCsvTransforms.create_edge_id_column(applymapping4, '~from', '~to')\n",
    "selectfields4 = SelectFields.apply(frame = applymapping4, paths = [\"~id\", \"~from\", \"~to\"], transformation_ctx = \"selectfields4\")\n",
    "\n",
    "selectfields4.toDF().foreachPartition(neptune.add_edges('PRODUCT'))\n",
    "\n",
    "update_checkpoint(neptune, order_table, newcheckpoint)\n",
    "\n",
    "job.commit()\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
