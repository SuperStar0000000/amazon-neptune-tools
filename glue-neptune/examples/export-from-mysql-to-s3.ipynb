{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.transforms import ApplyMapping\n",
    "from awsglue.transforms import RenameField\n",
    "from awsglue.transforms import SelectFields\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import format_string\n",
    "from glue_neptune.GremlinCsvTransforms import GremlinCsvTransforms\n",
    "\n",
    "glueContext = GlueContext(sc)\n",
    "\n",
    "job = Job(glueContext)\n",
    "job.init('rds-2-neptune', {})\n",
    "\n",
    "nodes_path = 's3://<path_to_nodes_directory>'\n",
    "edges_path = 's3://<path_to_edges_directory>'\n",
    "\n",
    "database = \"sales-order\"\n",
    "product_table = \"salesdb_product\"\n",
    "product_category_table = \"salesdb_product_category\"\n",
    "supplier_table = \"salesdb_supplier\"\n",
    "    \n",
    "def writeCsvFile(datasource, path):\n",
    "    dataframe = DynamicFrame.toDF(datasource).repartition(1)\n",
    "    datasource = DynamicFrame.fromDF(dataframe, glueContext, 'write-csv')\n",
    "    glueContext.write_dynamic_frame.from_options(frame = datasource, connection_type = \"s3\", connection_options = {\"path\": path}, format = \"csv\", transformation_ctx = \"write-csv\")  \n",
    "\n",
    "# Product vertices\n",
    "\n",
    "print \"Creating Product vertices...\"\n",
    "\n",
    "datasource0 = glueContext.create_dynamic_frame.from_catalog(database = database, table_name = product_table, transformation_ctx = \"datasource0\")\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database = database, table_name = product_category_table, transformation_ctx = \"datasource1\")\n",
    "datasource2 = datasource0.join( [\"CATEGORY_ID\"],[\"CATEGORY_ID\"], datasource1, transformation_ctx = \"join\")\n",
    "\n",
    "applymapping1 = ApplyMapping.apply(frame = datasource2, mappings = [(\"NAME\", \"string\", \"name:String\", \"string\"), (\"UNIT_PRICE\", \"decimal(10,2)\", \"unitPrice\", \"decimal(10,2)\"), (\"PRODUCT_ID\", \"int\", \"productId\", \"int\"), (\"QUANTITY_PER_UNIT\", \"int\", \"quantityPerUnit:Int\", \"int\"), (\"CATEGORY_ID\", \"int\", \"category_id\", \"int\"), (\"SUPPLIER_ID\", \"int\", \"supplierId\", \"int\"), (\"CATEGORY_NAME\", \"string\", \"category:String\", \"string\"), (\"DESCRIPTION\", \"string\", \"description:String\", \"string\"), (\"IMAGE_URL\", \"string\", \"imageUrl:String\", \"string\")], transformation_ctx = \"applymapping1\")\n",
    "applymapping1 = GremlinCsvTransforms.create_prefixed_columns(applymapping1, [('~id', 'productId', 'p'),('~to', 'supplierId', 's')])\n",
    "selectfields1 = SelectFields.apply(frame = applymapping1, paths = [\"~id\", \"name:String\", \"category:String\", \"description:String\", \"unitPrice\", \"quantityPerUnit:Int\", \"imageUrl:String\"], transformation_ctx = \"selectfields1\")\n",
    "\n",
    "writeCsvFile(GremlinCsvTransforms.addLabel(selectfields1, 'Product'), nodes_path)\n",
    "\n",
    "# SUPPLIER edges\n",
    "\n",
    "print \"Creating SUPPLIER edges...\"\n",
    "\n",
    "applymapping1 = RenameField.apply(applymapping1, \"~id\", \"~from\")\n",
    "applymapping1 = GremlinCsvTransforms.create_edge_id_column(applymapping1, '~from', '~to')\n",
    "selectfields2 = SelectFields.apply(frame = applymapping1, paths = [\"~id\", \"~from\", \"~to\"], transformation_ctx = \"selectfields2\")\n",
    "\n",
    "writeCsvFile(GremlinCsvTransforms.addLabel(selectfields2, 'SUPPLIER'), edges_path)\n",
    "\n",
    "# Supplier vertices\n",
    "\n",
    "print \"Creating Supplier vertices...\"\n",
    "\n",
    "datasource3 = glueContext.create_dynamic_frame.from_catalog(database = database, table_name = supplier_table, transformation_ctx = \"datasource3\")\n",
    "\n",
    "applymapping2 = ApplyMapping.apply(frame = datasource3, mappings = [(\"COUNTRY\", \"string\", \"country:String\", \"string\"), (\"ADDRESS\", \"string\", \"address:String\", \"string\"), (\"NAME\", \"string\", \"name:String\", \"string\"), (\"STATE\", \"string\", \"state:String\", \"string\"), (\"SUPPLIER_ID\", \"int\", \"supplierId\", \"int\"), (\"CITY\", \"string\", \"city:String\", \"string\"), (\"PHONE\", \"string\", \"phone:String\", \"string\")], transformation_ctx = \"applymapping1\")\n",
    "applymapping2 = GremlinCsvTransforms.create_prefixed_columns(applymapping2, [('~id', 'supplierId', 's')])\n",
    "selectfields3 = SelectFields.apply(frame = applymapping2, paths = [\"~id\", \"country:String\", \"address:String\", \"city:String\", \"phone:String\", \"name:String\", \"state:String\"], transformation_ctx = \"selectfields3\")\n",
    "\n",
    "writeCsvFile(GremlinCsvTransforms.addLabel(selectfields3, 'Supplier'), nodes_path)\n",
    "\n",
    "# End\n",
    "\n",
    "job.commit()\n",
    "\n",
    "print \"Done\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
